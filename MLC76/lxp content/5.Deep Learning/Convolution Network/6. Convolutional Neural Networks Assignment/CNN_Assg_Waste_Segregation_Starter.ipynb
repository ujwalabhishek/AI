{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lf5lYawIw8tE"
   },
   "source": [
    "# **Waste Material Segregation for Improving Waste Management**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY1InIbkw80B"
   },
   "source": [
    "## **Objective**\n",
    "\n",
    "The objective of this project is to implement an effective waste material segregation system using convolutional neural networks (CNNs) that categorises waste into distinct groups. This process enhances recycling efficiency, minimises environmental pollution, and promotes sustainable waste management practices.\n",
    "\n",
    "The key goals are:\n",
    "\n",
    "* Accurately classify waste materials into categories like cardboard, glass, paper, and plastic.\n",
    "* Improve waste segregation efficiency to support recycling and reduce landfill waste.\n",
    "* Understand the properties of different waste materials to optimise sorting methods for sustainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZGTCfyUxalZ"
   },
   "source": [
    "## **Data Understanding**\n",
    "\n",
    "The Dataset consists of images of some common waste materials.\n",
    "\n",
    "1. Food Waste\n",
    "2. Metal\n",
    "3. Paper\n",
    "4. Plastic\n",
    "5. Other\n",
    "6. Cardboard\n",
    "7. Glass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZJtmMnzQjAr"
   },
   "source": [
    "**Data Description**\n",
    "\n",
    "* The dataset consists of multiple folders, each representing a specific class, such as `Cardboard`, `Food_Waste`, and `Metal`.\n",
    "* Within each folder, there are images of objects that belong to that category.\n",
    "* However, these items are not further subcategorised. <br> For instance, the `Food_Waste` folder may contain images of items like coffee grounds, teabags, and fruit peels, without explicitly stating that they are actually coffee grounds or teabags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBFt43WDzWSJ"
   },
   "source": [
    "## **1. Load the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dfy0rjJ1yzFl"
   },
   "source": [
    "Load and unzip the dataset zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N35LLuWXzUQH"
   },
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmZo7m1-J_Ou"
   },
   "outputs": [],
   "source": [
    "# Recommended versions:\n",
    "\n",
    "# numpy version: 1.26.4\n",
    "# pandas version: 2.2.2\n",
    "# seaborn version: 0.13.2\n",
    "# matplotlib version: 3.10.0\n",
    "# PIL version: 11.1.0\n",
    "# tensorflow version: 2.18.0\n",
    "# keras version: 3.8.0\n",
    "# sklearn version: 1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dzM50pygphUe"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\ujwal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\ujwal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNAzJi1c9WAX"
   },
   "source": [
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TM1qn2DKtjR6"
   },
   "outputs": [],
   "source": [
    "# Load and unzip the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDp_EWxVOhUu"
   },
   "source": [
    "## **2. Data Preparation** <font color=red> [25 marks] </font><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7Ac8VxvjWnw"
   },
   "source": [
    "### **2.1 Load and Preprocess Images** <font color=red> [8 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghmtINrMXDMy"
   },
   "source": [
    "Let us create a function to load the images first. We can then directly use this function while loading images of the different categories to load and crop them in a single step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZQ1UZNfQCWX"
   },
   "source": [
    "#### **2.1.1** <font color=red> [3 marks] </font><br>\n",
    "Create a function to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6klNk9rcAtr"
   },
   "outputs": [],
   "source": [
    "# Create a function to load the raw images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J01VQrLhQsxx"
   },
   "source": [
    "#### **2.1.2** <font color=red> [5 marks] </font><br>\n",
    "Load images and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C9Oo0PTtYLf"
   },
   "source": [
    "Load the images from the dataset directory. Labels of images are present in the subdirectories.\n",
    "\n",
    "Verify if the images and labels are loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm2zlZbmamzy"
   },
   "outputs": [],
   "source": [
    "# Get the images and their labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26Is-EwKuyGf"
   },
   "source": [
    "Perform any operations, if needed, on the images and labels to get them into the desired format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I64rs77bkAYk"
   },
   "source": [
    "### **2.2 Data Visualisation** <font color=red> [9 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCAepbyAQdI2"
   },
   "source": [
    "#### **2.2.1** <font color=red> [3 marks] </font><br>\n",
    "Create a bar plot to display the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gm5LuWSFqTac"
   },
   "outputs": [],
   "source": [
    "# Visualise Data Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNWsPfTzRh7x"
   },
   "source": [
    "#### **2.2.2** <font color=red> [3 marks] </font><br>\n",
    "Visualise some sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37yXZzfLyOWt"
   },
   "outputs": [],
   "source": [
    "# Visualise Sample Images (across different labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrxdFzNigaYG"
   },
   "source": [
    "#### **2.2.3** <font color=red> [3 marks] </font><br>\n",
    "Based on the smallest and largest image dimensions, resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyVvjNXqgIGe"
   },
   "outputs": [],
   "source": [
    "# Find the smallest and largest image dimensions from the data set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fz7EutUrgKFZ"
   },
   "outputs": [],
   "source": [
    "# Resize the image dimensions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCB8uOckR5li"
   },
   "source": [
    "### **2.3 Encoding the classes** <font color=red> [3 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdC4dpTWt9eo"
   },
   "source": [
    "There are seven classes present in the data.\n",
    "\n",
    "We have extracted the images and their labels, and visualised their distribution. Now, we need to perform encoding on the labels. Encode the labels suitably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Nwd0Ztvkf7K"
   },
   "source": [
    "####**2.3.1** <font color=red> [3 marks] </font><br>\n",
    "Encode the target class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkyXDQN-660s"
   },
   "outputs": [],
   "source": [
    "# Encode the labels suitably\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNBM4hsuSaoj"
   },
   "source": [
    "### **2.4 Data Splitting** <font color=red> [5 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0xw-Qlh29cZ"
   },
   "source": [
    "#### **2.4.1** <font color=red> [5 marks] </font><br>\n",
    "Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TErpx_JOkwjO"
   },
   "outputs": [],
   "source": [
    "# Assign specified parts of the dataset to train and validation sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mILXPeY-X-zP"
   },
   "source": [
    "## **3. Model Building and Evaluation** <font color=red> [20 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E0afHwy5M_i"
   },
   "source": [
    "### **3.1 Model building and training** <font color=red> [15 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsu8K3tL5a5Q"
   },
   "source": [
    "#### **3.1.1** <font color=red> [10 marks] </font><br>\n",
    "Build and compile the model. Use 3 convolutional layers. Add suitable normalisation, dropout, and fully connected layers to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awW9V2lmMK_d"
   },
   "source": [
    "Test out different configurations and report the results in conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oD7-2EXdz_Cl"
   },
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t4duT1wX5wS"
   },
   "source": [
    "#### **3.1.2** <font color=red> [5 marks] </font><br>\n",
    "Train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcrEzo51Qj6w"
   },
   "source": [
    "Use appropriate metrics and callbacks as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7Ut0BicH_I8"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWT-bIj9YVzh"
   },
   "source": [
    "### **3.2 Model Testing and Evaluation** <font color=red> [5 marks] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjhU3i5v59d6"
   },
   "source": [
    "#### **3.2.1** <font color=red> [5 marks] </font><br>\n",
    "Evaluate the model on test dataset. Derive appropriate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_MtfUM_4y7j"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the test set; display suitable metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utro5JdHS0JM"
   },
   "source": [
    "## **4. Data Augmentation** <font color=red> [optional] </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T6QlG4eS4xi"
   },
   "source": [
    "#### **4.1 Create a Data Augmentation Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AXlfuoa4jQV"
   },
   "source": [
    "##### **4.1.1**\n",
    "Define augmentation steps for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbHCwkX0dq0R"
   },
   "outputs": [],
   "source": [
    "# Define augmentation steps to augment images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07i11vgMEmM2"
   },
   "source": [
    "Augment and resample the images.\n",
    "In case of class imbalance, you can also perform adequate undersampling on the majority class and augment those images to ensure consistency in the input datasets for both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chvmgE2r4xPZ"
   },
   "source": [
    "Augment the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-JBheeYFS8d"
   },
   "outputs": [],
   "source": [
    "# Create a function to augment the images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ddy1y1nPIlvM"
   },
   "outputs": [],
   "source": [
    "# Create the augmented training dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZYekkw9TCvP"
   },
   "source": [
    "##### **4.1.2**\n",
    "\n",
    "Train the model on the new augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBcRbt57FEct"
   },
   "outputs": [],
   "source": [
    "# Train the model using augmented images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFPuXAvHkJVz"
   },
   "source": [
    "## **5. Conclusions** <font color = red> [5 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33tWCHjpO5hH"
   },
   "source": [
    "#### **5.1 Conclude with outcomes and insights gained** <font color =red> [5 marks] </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3e1TLo2kWi0"
   },
   "source": [
    "* Report your findings about the data\n",
    "* Report model training results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1KW2JSuqBLb3DdmqZSAHtN2K0gX8C2HcV",
     "timestamp": 1740722968634
    },
    {
     "file_id": "1XXsgvgvRpr1OqI_K70kBWgfsI9bByK3r",
     "timestamp": 1738303842187
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
