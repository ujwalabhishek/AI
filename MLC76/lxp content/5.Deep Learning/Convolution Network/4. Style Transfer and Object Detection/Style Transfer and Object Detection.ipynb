{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf81758-803d-49cd-b043-7427ca904fa9",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "# Introduction to Style Transfer - Part 1\n",
    "\n",
    "# Introduction to Style Transfer - Part 2\n",
    "\n",
    "# Introduction to Style Transfer - Ungraded Assesment\n",
    "\n",
    "# Style Loss and the Gram Matrix - Part 1\n",
    "\n",
    "# Style Loss and the Gram Matrix - Ungraded Assesment\n",
    "\n",
    "# Style Loss and the Gram Matrix - Part 2\n",
    "\n",
    "# Style Loss and the Gram Matrix - Part 3\n",
    "\n",
    "# Style Loss and the Gram Matrix - Ungraded Assesment\n",
    "\n",
    "# Loss Function - Part 1\n",
    "\n",
    "# Loss Function - Part 2\n",
    "\n",
    "# Object Detection - I\n",
    "\n",
    "# Object Detection - II\n",
    "\n",
    "# Summary\n",
    "\n",
    "# Style Transfer Notebook \n",
    "\n",
    "In this segment, you will see the python implementation of style transfer. For the demonstration, let’s take the image of a rabbit as the content image and splash of colours as the style image. You can, of course, use any set of images for your notebook.\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Please note that there is a slight change in notation. The candidate image is denoted by ‘generated image’ in the notebook.\n",
    "\n",
    " \n",
    "\n",
    "In the case of transfer learning, we use a pre-trained model, VGGNet in our case, and remove its last fully connected layer since our task is not to classify the image. Here, we use the pre-trained weights of the model to update the candidate image instead of updating the model weights. Since there are no prebuilt functions to train these type of networks in Keras,  you will see that we will use lots of custom functions.\n",
    "\n",
    " \n",
    "\n",
    "It is highly recommended to download and run the code while going through the video. \n",
    "\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://github.com/ContentUpgrad/Convolutional-Neural-Networks/blob/main/Style%20Transfer%20and%20Object%20Detection/Style%2Btransfer.rar\">Style Transfer Notebook</a></h4></div>\n",
    "\n",
    "You learned how to load the VGG-19 model, preprocess the data, and then define the placeholder for the generated image.  Next, we will define the loss functions, define the layer from which we want to extract the features, define a custom Keras function, and train the pixels of the generated image. \n",
    "\n",
    "\n",
    "We have trained for 10 iterations. You can see the difference between the generated image at iteration-0 and iteration-5 and iteration-9. As the number of iterations increases, there is a clear effect of the style image on the generated image.\n",
    "\n",
    "\n",
    "In the next few segments, you'll learn another important application of CNNs - object detection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcba1df-fbff-4b70-abd3-0e95fdb4b1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
