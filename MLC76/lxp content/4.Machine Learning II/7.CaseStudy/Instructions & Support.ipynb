{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9946f45-3eb3-4cfd-9d49-179666f34368",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div class=\"MuiBox-root css-1ryrkgo\"><div data-resource-woolf=\"683d4f9ccf1d962fcea30c7c_C676012516107984f6abdf19c_V1\"><div class=\"MuiBox-root css-1hqgrfy-fullWidthWithAssetNameContainer\"><div class=\"MuiBox-root css-qgb4hw\"><div class=\"MuiBox-root css-1xzog2f\" id=\"switch-player-content\"></div><div class=\"MuiBox-root css-j7qwjs\" data-testid=\"switch-player\"><div class=\"MuiBox-root css-lrle2m-container\" data-testid=\"online-editor-player\"><div class=\"text_component\" data-testid=\"online-editor-content\"><p><strong>Additional Support</strong><br><br>This page provides guidance on common challenges, best practices and additional resources for selected steps in the assignment.<br><br>&nbsp;</p><h2 dir=\"ltr\"><strong><em>Data Preprocessing and Feature Engineering</em></strong></h2><p dir=\"ltr\"><strong>Redundant Values and Columns</strong></p><p dir=\"ltr\"><strong>Why do we need to handle redundant values and columns?</strong></p><p dir=\"ltr\">Redundant data, whether in the form of entire columns or specific values within columns, can negatively impact the performance, interpretability and efficiency of your machine learning models.&nbsp;</p><p dir=\"ltr\">The possible reasons for data redundancy are the following:</p><ul><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Unique identifiers and irrelevant information</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Missing or empty data</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Duplicate or highly correlated features</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Low variance or skewed data</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Illogical or invalid values</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Features with low predictive power</p></li></ul><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>Fixing Datatypes</strong></p><p dir=\"ltr\"><strong>Why do we need to separate categorical features from numerical ones?</strong></p><ul><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Machine learning models treat categorical and numerical features differently. Categorical variables often require encoding (one-hot or label encoding), whereas numerical features can be used directly in computations.</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Keeping them separate initially ensures correct transformations without unintended numerical operations on categorical data.</p></li></ul><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>Resampling</strong></p><p dir=\"ltr\">Resampling addresses class imbalance, ensuring the model is not biased towards the majority class and can effectively learn patterns from all classes. Class imbalance can lead to:</p><ul><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Poor learning of the minority class</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">High overall accuracy but poor performance on the minority class</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Poor generalisation of unseen data</p></li></ul><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>Why do we need to handle the class imbalance?</strong></p><p dir=\"ltr\">If one class is under-represented, the model might perform well overall but fail to identify minority class patterns accurately. Resampling helps the model generalise better, especially for minority class predictions.</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>How to perform resampling?</strong></p><p dir=\"ltr\">You can use different resampling techniques to handle the class imbalance, and they serve different purposes.&nbsp;</p><ol><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\"><strong>Random undersampling:</strong> In this method, you select fewer data points from the majority class to balance the classes. If the minority class has 500 data points, you would take 500 from the majority class, creating balance. However, this approach is often ineffective as it discards over 99% of the original data, potentially causing bias. You can learn about it <a target=\"_blank\" href=\"https://imbalanced-learn.org/dev/references/generated/imblearn.under_sampling.RandomUnderSampler.html\">here</a>.</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\"><strong>Random oversampling:</strong> Using this method, you can add more observations from the minority class by replication. Although this method does not add any new information, there is no information loss. It may also exaggerate the existing information to a certain extent, leading to the problem of overfitting. You can learn about it <a target=\"_blank\" href=\"https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.RandomOverSampler.html\">here</a>.</p></li></ol><p>&nbsp;</p><p dir=\"ltr\" style=\"text-align: center;\"><img data-width=\"990\" data-height=\"413\" height=\"250.3030303030303\" width=\"600\" src=\"https://images.upgrad.com/c21d73c8-9fd5-45bf-9caf-77b28cbcf43d-image3.png\"></p><p>&nbsp;</p><p dir=\"ltr\">You can explore other resampling techniques by accessing the following links:</p><ul><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\"><a target=\"_blank\" href=\"https://imbalanced-learn.org/dev/references/under_sampling.html\">Undersampling Techniques</a></p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\"><a target=\"_blank\" href=\"https://imbalanced-learn.org/dev/references/over_sampling.html\">Oversampling Techniques</a></p></li></ul><p dir=\"ltr\" role=\"presentation\"><br><strong>NOTE:</strong> Always<strong> apply resampling only on the training set</strong>, not on the test set, to avoid data leakage. If applied to the test set, the model may memorise test data, leading to misleading performance. Split the data into train and test sets first before handling class imbalance.</p><p dir=\"ltr\" role=\"presentation\">&nbsp;</p><p dir=\"ltr\"><strong>Feature Creation</strong></p><p dir=\"ltr\"><strong>Why do we need to create a new feature?</strong></p><p dir=\"ltr\">Creating new features enhances the information available to the model, helping it capture complex relationships and patterns that may not be obvious from the original data. Well-designed features can introduce domain knowledge and improve the model’s ability to distinguish between classes, leading to better performance.</p><p dir=\"ltr\">You can create a new feature by:</p><ul><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\"><strong>Generating interaction terms: </strong>Create new features by multiplying or combining two or more existing features to capture interactions. For example, create a ‘total purchase amount’ by multiplying ‘price’ and ‘quantity’.</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\"><strong>Extracting information from date/time:</strong> Derive ‘day of the week’ or ‘month’ from a timestamp to capture seasonal trends.</p></li></ul><p dir=\"ltr\">Try using domain knowledge to identify meaningful combinations or transformations, and explore various feature creation strategies to improve your model's ability to learn and generalise.</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>Combine Values in Categorical Columns</strong></p><p dir=\"ltr\"><strong>Why do we need to combine or group low-frequency values in categorical columns?</strong></p><p dir=\"ltr\">Grouping infrequent categories reduces model complexity by decreasing the number of unique values, making the model easier to interpret and train. It also improves generalisation by helping the model handle unseen or new categories more effectively in future data.</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><em>Let’s understand this using an example.&nbsp;</em></p><p dir=\"ltr\">Suppose you have a data set with a categorical column ‘Brand’ containing the following values: Apple, Moto, Samsung, Vivo, Oppo and Nothing.&nbsp;</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\">Let's visualise their initial distribution in the graph below.</p><p>&nbsp;</p><p dir=\"ltr\" style=\"text-align: center;\"><img data-width=\"915\" data-height=\"602\" height=\"394.75409836065575\" width=\"600\" src=\"https://images.upgrad.com/c8b0ae5b-11fb-47d0-9a91-55d8733dab3a-image2.png\"></p><p>&nbsp;</p><p dir=\"ltr\">As you can see, Nothing, Vivo and Oppo appear much less frequently than other categories. Since these low-frequency values are unlikely to contribute much to the prediction, combining them into a single category called ‘Other’ can help reduce sparsity and improve model generalisation.</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\">Let's combine Nothing, Vivo and Oppo into a single category, ‘Other’ and visualise the updated distribution:</p><p dir=\"ltr\">&nbsp;</p><p>&nbsp;</p><p dir=\"ltr\" style=\"text-align: center;\"><img data-width=\"914\" data-height=\"591\" height=\"387.96498905908095\" width=\"600\" src=\"https://images.upgrad.com/258fdd28-4493-47b7-aa62-67f50f11bf80-image1.png\"></p><p>&nbsp;</p><p dir=\"ltr\">As you can see, the combined ‘Other’ category now has a meaningful count relative to other categories, which helps the model generalise better and reduces the risk of overfitting to rare values.</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>Feature Scaling</strong></p><p dir=\"ltr\"><strong>Why do we need to scale the features before model building?</strong></p><p dir=\"ltr\">Feature scaling ensures that features with different scales do not disproportionately influence the model's learning process.</p><p dir=\"ltr\"><strong>For example</strong>, if a data set has ‘Product Price’ (ranging from $1 to $1000) and ‘Customer Rating’ (ranging from 1 to 5), scaling ensures that the price feature does not dominate the model's learning process.</p><p dir=\"ltr\">&nbsp;</p><h2 dir=\"ltr\"><strong><em>EDA</em></strong></h2><p dir=\"ltr\"><strong>Correlation Analysis</strong></p><p dir=\"ltr\"><strong>What does correlation analysis reveal about the features?</strong></p><p dir=\"ltr\">Correlation analysis of numerical features helps to understand the strength and direction of the relationship between two or more numerical variables. This helps in:</p><ul><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Detecting highly correlated features, as multicollinearity can affect model interpretation and stability</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Identifying and removing redundant features, improving model efficiency and clarity</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Understanding feature relationships, guiding better feature engineering</p></li></ul><p dir=\"ltr\">You can learn more about it <a target=\"_blank\" href=\"https://seaborn.pydata.org/generated/seaborn.heatmap.html\">here</a>.</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>Target Likelihood Analysis</strong></p><p dir=\"ltr\"><strong>What does the target likelihood analysis reveal about the features?</strong></p><p dir=\"ltr\">As the name suggests, the target likelihood analysis examines the relationship between categorical variables and the target variable by calculating the likelihood of the target event for each category of a categorical feature. This helps in:</p><ul><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Identifying which categorical features have the strongest influence on the target variable</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Revealing how different categories are associated with the target event, offering valuable insights</p></li><li dir=\"ltr\" aria-level=\"1\"><p dir=\"ltr\" role=\"presentation\">Making decisions on feature transformations or combining categories to improve model performance</p></li></ul><p dir=\"ltr\">&nbsp;</p><h2 dir=\"ltr\"><em><strong>Model Building</strong></em></h2><p dir=\"ltr\"><strong>Recursive Feature Elimination (RFECV)</strong></p><p dir=\"ltr\"><strong>What is RFECV, and how does it select features?</strong></p><p dir=\"ltr\">RFECV is an extension of Recursive Feature Elimination (RFE) that automates feature selection by using cross-validation to determine the optimal number of features. It iteratively removes the least important features while refitting a model, ensuring that only the most relevant features are retained. Performance metrics such as R-squared or accuracy guide the selection process, preventing underfitting or overfitting. You can learn more about it <a target=\"_blank\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html\">here</a>.</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>How are manual, RFE and RFECV-based feature selections different from one another?</strong></p><p dir=\"ltr\"><strong>Manual selection: </strong>Relies on domain knowledge and exploratory analysis. It is subjective and time-consuming and may miss hidden patterns.</p><p dir=\"ltr\"><strong>RFE:</strong> Iteratively removes the least important features based on model ranking. Requires manual selection of the optimal feature count and lacks cross-validation</p><p dir=\"ltr\"><strong>RFECV: </strong>Extends RFE by using cross-validation to automatically determine the best features, reducing overfitting risks but is computationally expensive</p><p dir=\"ltr\">&nbsp;</p><p dir=\"ltr\"><strong>Hyperparameter Tuning</strong></p><p dir=\"ltr\">Hyperparameter tuning optimises a model's learning process, helping prevent overfitting and underfitting while improving performance on the given data. Since hyperparameters control the model's learning behaviour, fine-tuning them can significantly impact accuracy, precision, recall or other key metrics.</p><p dir=\"ltr\">You can learn more about tuning different models using the following links:</p><p dir=\"ltr\"><a target=\"_blank\" href=\"https://www.geeksforgeeks.org/random-forest-hyperparameter-tuning-in-python/\">Hyperparameter Tuning - Random Forest&nbsp;</a></p><p dir=\"ltr\"><a target=\"_blank\" href=\"https://www.geeksforgeeks.org/how-to-tune-a-decision-tree-in-hyperparameter-tuning/\">Hyperparameter tuning - Decision Tree</a></p></div></div><div class=\"MuiBox-root css-0\"></div></div></div></div></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa1b8df-6cef-4774-9f8b-9f4e8bcd60f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
